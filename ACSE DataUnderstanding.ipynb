{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb1f8f9e787ceb86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:23:41.421965Z",
     "start_time": "2025-03-08T05:23:41.419241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nProject: ACSE Supermarket Data Analysis - Data Understanding\\nAuthors: Jasmine Xu, Amelie Ndongozi, Jiyuan Xin, Miao Yin, Yifeng Dong\\nDate:    March 8 2025\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Project: ACSE Supermarket Data Analysis - Data Understanding\n",
    "Authors: Jasmine Xu, Amelie Ndongozi, Jiyuan Xin, Miao Yin, Yifeng Dong\n",
    "Date:    March 8 2025\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904ee19adb0e328",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1c4c6c8608a3ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:23:41.583783Z",
     "start_time": "2025-03-08T05:23:41.537954Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe4b57b10559fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:23:41.630804Z",
     "start_time": "2025-03-08T05:23:41.599710Z"
    }
   },
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=':memory:') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9595fcc5254913b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:23:41.639095Z",
     "start_time": "2025-03-08T05:23:41.637379Z"
    }
   },
   "outputs": [],
   "source": [
    "#duckdb.execute(\"COPY (SELECT * FROM read_csv('ACSE Data/products.csv', parallel=True)) TO 'ACSE Data/products.parquet' (FORMAT 'parquet');\")\n",
    "products_path = 'ACSE Data/products.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967747f37f161027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:23:41.645796Z",
     "start_time": "2025-03-08T05:23:41.644352Z"
    }
   },
   "outputs": [],
   "source": [
    "# duckdb.execute(\"COPY (SELECT * FROM read_csv('ACSE Data/transactions.csv', parallel=True)) TO 'ACSE Data/transactions.parquet' (FORMAT 'parquet');\")\n",
    "trans_path = 'ACSE Data/transactions.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a237875cae6c456",
   "metadata": {},
   "source": [
    "### 1.1 Understand the Store Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77770fce-dde8-454d-9d57-866a74d57fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: No files found that match the pattern \"ACSE Data/transactions.parquet\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m      1\u001b[0m query_store_distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mWITH store_customer_counts AS (\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m  SELECT \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124mORDER BY num_stores DESC;\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m df_store_distribution \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39mquery(query_store_distribution)\u001b[38;5;241m.\u001b[39mto_df()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_store_distribution)\n",
      "\u001b[1;31mIOException\u001b[0m: IO Error: No files found that match the pattern \"ACSE Data/transactions.parquet\""
     ]
    }
   ],
   "source": [
    "query_store_distribution = \"\"\"\n",
    "WITH store_customer_counts AS (\n",
    "  SELECT \n",
    "    store_id, \n",
    "    COUNT(DISTINCT cust_id) AS total_store_customers\n",
    "  FROM read_parquet('ACSE Data/transactions.parquet')\n",
    "  GROUP BY store_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    total_store_customers,\n",
    "    COUNT(*) AS num_stores,\n",
    "    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER () AS percentage\n",
    "FROM store_customer_counts\n",
    "GROUP BY total_store_customers\n",
    "ORDER BY num_stores DESC;\n",
    "\"\"\"\n",
    "df_store_distribution = duckdb.query(query_store_distribution).to_df()\n",
    "print(df_store_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c641dfec0308d8b",
   "metadata": {},
   "source": [
    "#Smallest store has 305 customers.\n",
    "Largest store has 780,607 customers.\n",
    "Many stores have 200,000+ customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c35a15096ed4c5",
   "metadata": {},
   "source": [
    "### 1.2 Understand Customer Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3811da2-b59a-4aa8-9d33-13b7d07e5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_distribution = \"\"\"\n",
    "WITH customer_spending AS (\n",
    "    SELECT \n",
    "        cust_id, \n",
    "        SUM(sales_amt) AS total_spent,\n",
    "        CASE \n",
    "            WHEN SUM(sales_amt) < 0 THEN 'negative_spender'\n",
    "            WHEN SUM(sales_amt) < 50 THEN 'low_spender'\n",
    "            WHEN SUM(sales_amt) < 100 THEN 'mid_spender'\n",
    "            WHEN SUM(sales_amt) < 1000 THEN 'high_spender'\n",
    "            ELSE 'vip'\n",
    "        END AS spending_segment\n",
    "    FROM read_parquet('ACSE Data/transactions.parquet')\n",
    "    GROUP BY cust_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    spending_segment,\n",
    "    COUNT(*) AS num_customers,\n",
    "    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER () AS percentage\n",
    "FROM customer_spending\n",
    "GROUP BY spending_segment\n",
    "ORDER BY num_customers DESC;\n",
    "\"\"\"\n",
    "df_distribution = duckdb.query(query_distribution).to_df()\n",
    "\n",
    "print(df_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac795177cb7122fb",
   "metadata": {},
   "source": [
    "#low_spenders (42.1%) and high_spenders (30.9%) dominate the dataset, while negative_spenders (0.47%) and VIPs (11.5%) are underrepresented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecde27f6c1497a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:23:42.996244Z",
     "start_time": "2025-03-08T05:23:41.660846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query to get the date range and count unique stores\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    MIN(trans_dt) AS start_date,\n",
    "    MAX(trans_dt) AS end_date,\n",
    "    COUNT(DISTINCT store_id) AS unique_stores\n",
    "FROM read_parquet('ACSE Data/transactions.parquet') \"\"\"\n",
    "df_summary = con.execute(query).fetchdf()\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e7f663e6d4e3a",
   "metadata": {},
   "source": [
    "##  1.3 Sample Transactions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66141f837ccf087c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:07:20.724787Z",
     "start_time": "2025-03-08T07:06:05.947955Z"
    }
   },
   "outputs": [],
   "source": [
    "query_trans = \"\"\"\n",
    "WITH customer_segments AS (\n",
    "  SELECT \n",
    "    store_id,\n",
    "    cust_id,\n",
    "    SUM(sales_amt) AS total_sales,\n",
    "    CASE \n",
    "      WHEN SUM(sales_amt) < 0 THEN 'negative_spender'\n",
    "      WHEN SUM(sales_amt) < 50 THEN 'low_spender'\n",
    "      WHEN SUM(sales_amt) < 100 THEN 'mid_spender'\n",
    "      WHEN SUM(sales_amt) < 1000 THEN 'high_spender'\n",
    "      ELSE 'vip'\n",
    "    END AS spending_segment\n",
    "  FROM read_parquet('ACSE Data/transactions.parquet')\n",
    "  GROUP BY store_id, cust_id\n",
    "),\n",
    "\n",
    "sampled_customers AS (\n",
    "  SELECT * \n",
    "  FROM customer_segments \n",
    "  WHERE RANDOM() <= 0.05\n",
    ")\n",
    "\n",
    "SELECT t.*\n",
    "FROM read_parquet('ACSE Data/transactions.parquet') t\n",
    "JOIN sampled_customers cs\n",
    "ON t.store_id = cs.store_id AND t.cust_id = cs.cust_id;\n",
    "\n",
    "\"\"\"\n",
    "df_transactions = con.execute(query_trans).fetchdf()\n",
    "print(\"Unique stores sampled:\", df_transactions['store_id'].nunique())\n",
    "print(df_transactions.shape)  \n",
    "print(df_transactions.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc3293a67dc8ba",
   "metadata": {},
   "source": [
    "## 1.4 Inspect the sampled data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bc6a696d44fbe",
   "metadata": {},
   "source": [
    "Q1: If all store has been sampled? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbc4ead2f56b33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:07:20.897278Z",
     "start_time": "2025-03-08T07:07:20.791847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print number of unique stores in the sampled data\n",
    "print(\"Unique stores sampled:\", df_transactions['store_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b44e62cc78f27",
   "metadata": {},
   "source": [
    "Q2: If the Date Range matches the original dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53d78924ce4f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:07:21.054104Z",
     "start_time": "2025-03-08T07:07:20.927197Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check Date Range\n",
    "start_date = df_transactions['trans_dt'].min()\n",
    "end_date = df_transactions['trans_dt'].max()\n",
    "\n",
    "print(f\"Sampled Transactions Date Range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c1ff7ab129e220",
   "metadata": {},
   "source": [
    "Q3: If the distribution is the same as the original dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a114f1adda927",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:07:25.049657Z",
     "start_time": "2025-03-08T07:07:21.094969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check Customer Spending Segment Distribution\n",
    "customer_distribution = df_transactions.groupby('cust_id')['sales_amt'].sum().reset_index()\n",
    "customer_distribution['spending_segment'] = pd.cut(\n",
    "    customer_distribution['sales_amt'],\n",
    "    bins=[-float('inf'), 0, 50, 100, 1000, float('inf')],\n",
    "    labels=['negative_spender', 'low_spender', 'mid_spender', 'high_spender', 'vip']\n",
    ")\n",
    "\n",
    "df_customer_dist = customer_distribution['spending_segment'].value_counts(normalize=True) * 100\n",
    "print(\"\\nCustomer Spending Distribution (as % of sampled data):\")\n",
    "print(df_customer_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb386141c087683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:07:29.062258Z",
     "start_time": "2025-03-08T07:07:25.094391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check Store-Level Customer Distribution\n",
    "store_customer_counts = df_transactions.groupby('store_id')['cust_id'].nunique().reset_index()\n",
    "store_customer_counts.columns = ['store_id', 'total_store_customers']\n",
    "\n",
    "df_store_dist = store_customer_counts['total_store_customers'].describe()\n",
    "print(\"\\nStore Customer Distribution Summary:\")\n",
    "print(df_store_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b34d5aa8eb90f6",
   "metadata": {},
   "source": [
    "## 1.5 Load Products Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:07:29.543216Z",
     "start_time": "2025-03-08T07:07:29.158997Z"
    }
   },
   "outputs": [],
   "source": [
    "df_products = duckdb.query(f\"SELECT * FROM read_parquet('{products_path}')\").fetchdf()\n",
    "print(df_products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052a995e22112a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:07:29.631204Z",
     "start_time": "2025-03-08T07:07:29.574305Z"
    }
   },
   "outputs": [],
   "source": [
    "# Register the Pandas DataFrame as a DuckDB table named \"df_transactions\" and 'df_products'\n",
    "con.register('df_transactions', df_transactions)\n",
    "con.register('df_products', df_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7dad1cdd694ee",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28968f4fbe0dfe0",
   "metadata": {},
   "source": [
    "## 2.1 Quick Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72757f30261d1c41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:25:01.877250Z",
     "start_time": "2025-03-08T05:25:01.871607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print data types for df_transactions\n",
    "print(\"Data types for df_transactions:\")\n",
    "print(df_transactions.dtypes)\n",
    "\n",
    "print(\"\\nDetailed info for df_transactions:\")\n",
    "print(df_transactions.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc135eef4d9df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:25:01.985313Z",
     "start_time": "2025-03-08T05:25:01.962878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print data types for df_products\n",
    "print(\"\\nData types for df_product:\")\n",
    "print(df_products.dtypes)\n",
    "print(\"\\nDetailed info for df_products:\")\n",
    "print(df_products.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7609fa8bdbee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:25:02.093134Z",
     "start_time": "2025-03-08T05:25:02.074024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic transactions table overview\n",
    "print(\"New Sampled transactions table Data:\")\n",
    "display(df_transactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b964da710e92782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:25:02.220627Z",
     "start_time": "2025-03-08T05:25:02.216193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic products table overview\n",
    "print(\"New Sampled products table Data:\")\n",
    "display(df_products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfa9a737267dd8",
   "metadata": {},
   "source": [
    "## 2.2 Check Null Value and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd627c5d0117da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:25:02.661071Z",
     "start_time": "2025-03-08T05:25:02.429413Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check Missing Values\n",
    "print(\"Missing Values in Trans Table\")\n",
    "print(df_transactions.isnull().sum())\n",
    "print(\"Missing Values in Products Table\")\n",
    "print(df_products.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b17a7a9f7e436",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:25:02.903089Z",
     "start_time": "2025-03-08T05:25:02.839217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for full duplicate rows in the products table\n",
    "duplicates_products = df_products[df_products.duplicated()]\n",
    "num_duplicates_products = duplicates_products.shape[0]\n",
    "print(f\"Total duplicate rows in the products table: {num_duplicates_products}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b363fb1a6c3de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:25:31.292526Z",
     "start_time": "2025-03-08T05:25:02.951803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for full duplicate rows in the transactions table\n",
    "duplicates_trans = df_transactions[df_transactions.duplicated()]\n",
    "num_duplicates_trans = duplicates_trans.shape[0]\n",
    "print(f\"Total duplicate rows in the transactions table: {num_duplicates_trans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab953b17080ff48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:25:31.390972Z",
     "start_time": "2025-03-08T05:25:31.316558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Full Duplicates in Products\n",
    "df_products = df_products.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfef6848c2d58a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:01.567476Z",
     "start_time": "2025-03-08T05:25:31.398597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Full Duplicates in transactions\n",
    "df_transactions = df_transactions.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a5a8c54c4495c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:01.617900Z",
     "start_time": "2025-03-08T05:26:01.585889Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_products.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edfe97819a866af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:01.934106Z",
     "start_time": "2025-03-08T05:26:01.656713Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting missing value\n",
    "import missingno as msno\n",
    "msno.matrix(df_products, figsize=(5,5))\n",
    "plt.title(\"Missing Data Pattern - Productws\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c02f672a63a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:02.004737Z",
     "start_time": "2025-03-08T05:26:01.959013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows where all values are null\n",
    "df_products_cleaned = df_products.dropna(how='all')\n",
    "\n",
    "# Fill missing values in prod_type with 'Unknown'\n",
    "df_products_cleaned['prod_type'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Display summary of missing values after cleaning\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df_products_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d98e63f0f3489",
   "metadata": {},
   "source": [
    "## 2.3 Check Product Categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff28ae31a40886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:13.197576Z",
     "start_time": "2025-03-08T05:26:02.075284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform a left join on prod_id to combine transaction details with product details\n",
    "df_combined = df_transactions.merge(\n",
    "    df_products,  \n",
    "    on='prod_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Merged Transactions and Products Table:\")\n",
    "display(df_combined.head())\n",
    "print(df_combined.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1bf449aa1569b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:18.831931Z",
     "start_time": "2025-03-08T05:26:13.331251Z"
    }
   },
   "outputs": [],
   "source": [
    "top_product_per_category = df_combined.loc[\n",
    "    df_combined.groupby('prod_category')['sales_amt'].idxmax(),\n",
    "    ['prod_category', 'prod_id', 'sales_amt']\n",
    "]\n",
    "\n",
    "category_sales_summary = df_combined.groupby('prod_category').agg(\n",
    "    total_sales_amt=('sales_amt', 'sum'), \n",
    "    total_sales_count=('sales_qty', 'sum') \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "category_sales_summary = category_sales_summary.merge(top_product_per_category, on='prod_category', how='left')\n",
    "category_sales_summary = category_sales_summary.sort_values(by='total_sales_amt', ascending=False)\n",
    "\n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "print(\"Sales Amount and Sales Count by Product category with Top Product:\")\n",
    "display(category_sales_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9508cb338101d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:20.310501Z",
     "start_time": "2025-03-08T05:26:19.010866Z"
    }
   },
   "outputs": [],
   "source": [
    "query_category_subcategory = f\"\"\"\n",
    "SELECT \n",
    "    prod_category,\n",
    "    prod_subcategory,\n",
    "    SUM(sales_amt) AS sales_amt\n",
    "FROM df_combined\n",
    "GROUP BY prod_category, prod_subcategory\n",
    "ORDER BY prod_category, sales_amt DESC\n",
    "\"\"\"\n",
    "\n",
    "df_category_subcategory = con.execute(query_category_subcategory).fetchdf()\n",
    "display(df_category_subcategory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba0a37ab45d92a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:46.419129Z",
     "start_time": "2025-03-08T05:26:20.339784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the Scanning errors , prod_id is 20093960 for all tables \n",
    "df_transactions = df_transactions[df_transactions['prod_id'] != 20093960]\n",
    "df_products = df_products[df_products['prod_id'] != 20093960]\n",
    "df_combined = df_combined[df_combined['prod_id'] != 20093960]\n",
    "# Display confirmation\n",
    "print(\"Removed prod_id 20093960 from all datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a2b7b6784e91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:26:46.589008Z",
     "start_time": "2025-03-08T05:26:46.554960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Register the Pandas DataFrame as a DuckDB table named \"df_combined\"\n",
    "con.register('df_combined',df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f024175d8d19f865",
   "metadata": {},
   "source": [
    "# Q1 Who are the best customers in terms of revenues, profits, transactions/store visits, number of products, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9f0fcd7206829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:27:08.995877Z",
     "start_time": "2025-03-08T05:26:55.373516Z"
    }
   },
   "outputs": [],
   "source": [
    "query_best_customers = \"\"\"\n",
    "        SELECT \n",
    "        t.cust_id, \n",
    "        COUNT(DISTINCT t.trans_id) AS total_transactions,\n",
    "        COUNT(DISTINCT t.store_id) AS total_store_visits,\n",
    "        COUNT(DISTINCT t.prod_id) AS total_products_purchased,\n",
    "        SUM(t.sales_amt) AS total_revenue\n",
    "    FROM df_combined t\n",
    "    GROUP BY t.cust_id\n",
    "\"\"\"\n",
    "\n",
    "df_analysis = con.execute(query_best_customers).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765a52bd424dc92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:27:10.921945Z",
     "start_time": "2025-03-08T05:27:09.021490Z"
    }
   },
   "outputs": [],
   "source": [
    "#best customers in terms of revenues\n",
    "df_revenue = df_analysis.groupby(\"cust_id\")[\"total_revenue\"].sum().reset_index()\n",
    "\n",
    "df_revenue = df_revenue.sort_values(by=\"total_revenue\", ascending=False)\n",
    "\n",
    "print(df_revenue.head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf1da3eca48907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T06:07:06.233355Z",
     "start_time": "2025-03-08T06:07:04.508404Z"
    }
   },
   "outputs": [],
   "source": [
    "#best customers in terms of transactions\n",
    "df_transactions = df_analysis.groupby(\"cust_id\")[\"total_transactions\"].sum().reset_index()\n",
    "\n",
    "df_transactions = df_transactions.sort_values(by=\"total_transactions\", ascending=False)\n",
    "\n",
    "print(df_transactions.head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4612da912b0a8b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:27:23.063412Z",
     "start_time": "2025-03-08T05:27:21.697527Z"
    }
   },
   "outputs": [],
   "source": [
    "#best customers in terms of store visits\n",
    "df_visits = df_analysis.groupby(\"cust_id\")[\"total_store_visits\"].sum().reset_index()\n",
    "\n",
    "df_visits = df_visits.sort_values(by=\"total_store_visits\", ascending=False)\n",
    "\n",
    "print(df_visits.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e67602cd4d9e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:27:24.584260Z",
     "start_time": "2025-03-08T05:27:23.104470Z"
    }
   },
   "outputs": [],
   "source": [
    "#best customers in terms of number of products\n",
    "df_products_purchased = df_analysis.groupby(\"cust_id\")[\"total_products_purchased\"].sum().reset_index()\n",
    "\n",
    "df_products_purchased = df_products_purchased.sort_values(by=\"total_products_purchased\", ascending=False)\n",
    "\n",
    "print(df_products_purchased.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3de3e76f8d238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:27:35.536849Z",
     "start_time": "2025-03-08T05:27:24.623673Z"
    }
   },
   "outputs": [],
   "source": [
    "best_100_customers = df_revenue.head(100)['cust_id']\n",
    "\n",
    "df_top100 = df_combined[df_combined['cust_id'].isin(best_100_customers)]\n",
    "\n",
    "df_top100['trans_dt'] = pd.to_datetime(df_top100['trans_dt'])\n",
    "\n",
    "df_top100['weekday'] = df_top100['trans_dt'].dt.day_name()\n",
    "\n",
    "df_top100_weekday = df_top100.groupby('weekday').size().reindex(\n",
    "    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    ")\n",
    "print(df_top100_weekday)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77887a6463aaa145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:27:45.661872Z",
     "start_time": "2025-03-08T05:27:35.698744Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_combined['trans_dt'] = pd.to_datetime(df_combined['trans_dt'])\n",
    "\n",
    "df_combined['weekday'] = df_combined['trans_dt'].dt.day_name()\n",
    "\n",
    "df_all_customers_weekday = df_combined.groupby('weekday').size().reindex(\n",
    "    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    ")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_all_customers_weekday.plot(kind='bar')\n",
    "\n",
    "plt.title('Overall Customer Transactions by week')\n",
    "plt.ylabel('Number of Transactions')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80eb835a16f29d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:05.588235Z",
     "start_time": "2025-03-08T05:27:45.690283Z"
    }
   },
   "outputs": [],
   "source": [
    "transaction_products = df_combined.groupby('trans_id')['prod_id'].nunique().reset_index(name='num_products')\n",
    "\n",
    "transaction_type_counts = transaction_products['num_products'].apply(\n",
    "    lambda x: 'Bulk Purchase' if x > 1 else 'Single Purchase'\n",
    ").value_counts()\n",
    "\n",
    "transaction_type_counts.plot(\n",
    "    kind='pie',\n",
    "    autopct='%1.1f%%',\n",
    "    title='Bulk Purchase vs Single Purchase Transactions',\n",
    "    ylabel='',\n",
    "    figsize=(6, 6)\n",
    ")\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b069fa0ff5c6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.852135Z",
     "start_time": "2025-03-08T05:28:05.628164Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "transactions_products = df_combined.groupby('trans_id')['prod_desc'].apply(set)\n",
    "\n",
    "combination_counter = Counter()\n",
    "for products in transactions_products:\n",
    "    if len(products) >= 2:\n",
    "        combination_counter.update(combinations(sorted(products), 2))\n",
    "\n",
    "common_combinations = pd.DataFrame(\n",
    "    combination_counter.most_common(10), columns=['Product Combination', 'Count']\n",
    ")\n",
    "\n",
    "comb_labels = [' + '.join(combo) for combo in combination_counter.keys()][:10]\n",
    "comb_counts = [count for count in combination_counter.values()][:10]\n",
    "\n",
    "plt.barh(comb_labels[::-1], comb_counts[::-1])\n",
    "\n",
    "plt.title('Top 10 Frequent Product Combinations')\n",
    "plt.xlabel('Number of Transactions')\n",
    "plt.ylabel('Product Combinations')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406091cc3affa1a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.928079Z",
     "start_time": "2025-03-08T00:20:59.147097Z"
    }
   },
   "outputs": [],
   "source": [
    "df_combined['cust_id_str'] = df_combined['cust_id'].astype(str)\n",
    "df_combined['is_rewards_member'] = df_combined['cust_id_str'].apply(\n",
    "    lambda x: 'Member' if x.startswith('1') else 'Non-Member'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83035bc99c59bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.928203Z",
     "start_time": "2025-03-08T00:21:14.435831Z"
    }
   },
   "outputs": [],
   "source": [
    "rewards_summary = df_combined.groupby('is_rewards_member').agg(\n",
    "    total_revenue=('sales_amt', 'sum'), \n",
    "    total_transactions=('trans_id', 'nunique'), \n",
    "    avg_revenue_per_trans=('sales_amt', 'mean'), \n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6753fb2facbf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.928293Z",
     "start_time": "2025-03-08T00:21:35.999795Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "barplot = sns.barplot(\n",
    "    data=rewards_summary, \n",
    "    x='is_rewards_member', \n",
    "    y='total_transactions', \n",
    "    palette='Blues'\n",
    ")\n",
    "\n",
    "for patch in barplot.patches:\n",
    "    height = patch.get_height()\n",
    "    x_pos = patch.get_x() + patch.get_width() / 2\n",
    "    barplot.text(\n",
    "        x_pos, height, \n",
    "        f'{height:,.0f}', \n",
    "        ha='center', va='bottom', \n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.title('Total Transactions: Member vs Non-Member', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Customer Type', fontsize=12)\n",
    "plt.ylabel('Total Transactions', fontsize=12)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14f3fff54a50d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.928454Z",
     "start_time": "2025-03-08T00:21:45.799185Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "barplot = sns.barplot(\n",
    "    data=rewards_summary, \n",
    "    x='is_rewards_member', \n",
    "    y='total_revenue', \n",
    "    palette='Blues'\n",
    ")\n",
    "\n",
    "for patch in barplot.patches:\n",
    "    height = patch.get_height()\n",
    "    x_pos = patch.get_x() + patch.get_width() / 2  \n",
    "    barplot.text(\n",
    "        x_pos, height,\n",
    "        f'{height:,.2f}', \n",
    "        ha='center', va='bottom', \n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.title('Total Revenue: Member vs Non-Member')\n",
    "plt.xlabel('Customer Type')\n",
    "plt.ylabel('Total Revenue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fe937a62f6b3e",
   "metadata": {},
   "source": [
    "# Q2. What are the products and product groups with the best volumes, revenues, profits, transactions, customers, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961e70379223c41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.928511Z",
     "start_time": "2025-03-08T00:21:55.535467Z"
    }
   },
   "outputs": [],
   "source": [
    "query_analysis = \"\"\"\n",
    "        SELECT \n",
    "        prod_id, \n",
    "        prod_desc, \n",
    "        prod_category, \n",
    "        prod_subcategory, \n",
    "        COUNT(DISTINCT trans_id) AS total_transactions, \n",
    "        COUNT(DISTINCT cust_id) AS unique_customers,\n",
    "        SUM(sales_qty) AS total_sales_volume,\n",
    "        SUM(sales_amt) AS total_revenue\n",
    "    FROM df_combined\n",
    "    GROUP BY prod_id, prod_desc, prod_category, prod_subcategory\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_analysis = con.execute(query_analysis).fetchdf()\n",
    "\n",
    "\n",
    "### Display By Revenues\n",
    "df_category_revenue = df_analysis.groupby(\"prod_category\")[\"total_revenue\"].sum().reset_index()\n",
    "\n",
    "df_category_revenue = df_category_revenue.sort_values(by=\"total_revenue\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "sns.barplot(data=df_category_revenue, x=\"prod_category\", y=\"total_revenue\", palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Total Revenue Distribution by Product Category\", fontsize=14)\n",
    "plt.xlabel(\"Product Category\", fontsize=12)\n",
    "plt.ylabel(\"Total Revenue\", fontsize=6)\n",
    "plt.xticks(rotation=45, ha=\"right\") \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ce8bd17ea7b54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.959594Z",
     "start_time": "2025-03-08T00:23:36.873890Z"
    }
   },
   "outputs": [],
   "source": [
    "### Display By Total Volume\n",
    "df_category_sales = df_analysis.groupby(\"prod_category\")[\"total_sales_volume\"].sum().reset_index()\n",
    "df_category_sales = df_category_sales.sort_values(by=\"total_sales_volume\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "sns.barplot(data=df_category_sales, x=\"prod_category\", y=\"total_sales_volume\", palette=\"magma\")\n",
    "\n",
    "plt.title(\"Total Sales Volume Distribution by Product Category\", fontsize=14)\n",
    "plt.xlabel(\"Product Category\", fontsize=12)\n",
    "plt.ylabel(\"Total Sales Volume\", fontsize=6)\n",
    "plt.xticks(rotation=45, ha=\"right\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd13e89a228571e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.959860Z",
     "start_time": "2025-03-08T00:23:37.167496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display By Total Transaction\n",
    "df_category_transactions = df_analysis.groupby(\"prod_category\")[\"total_transactions\"].sum().reset_index()\n",
    "df_category_transactions = df_category_transactions.sort_values(by=\"total_transactions\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "sns.barplot(data=df_category_transactions, x=\"prod_category\", y=\"total_transactions\", palette=\"coolwarm\")\n",
    "\n",
    "plt.title(\"Total Transactions Distribution by Product Category\", fontsize=14)\n",
    "plt.xlabel(\"Product Category\", fontsize=12)\n",
    "plt.ylabel(\"Total Transactions\", fontsize=6)\n",
    "plt.xticks(rotation=45, ha=\"right\") \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744e043f937ef46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.959938Z",
     "start_time": "2025-03-08T00:23:46.576003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based On Number of Customers\n",
    "df_category_customers = df_analysis.groupby(\"prod_category\")[\"unique_customers\"].sum().reset_index()\n",
    "df_category_customers = df_category_customers.sort_values(by=\"unique_customers\", ascending=False)\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "sns.barplot(data=df_category_customers, x=\"prod_category\", y=\"unique_customers\", palette=\"Blues_r\")\n",
    "\n",
    "plt.title(\"Unique Customers Distribution by Product Category\", fontsize=14)\n",
    "plt.xlabel(\"Product Category\", fontsize=12)\n",
    "plt.ylabel(\"Unique Customers\", fontsize=6)\n",
    "plt.xticks(rotation=45, ha=\"right\")  \n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03505ca2a143f63",
   "metadata": {},
   "source": [
    "# Q3. Which stores rank the highest in volumes, revenues, profits, transactions, customers, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd0857995bc0b4",
   "metadata": {},
   "source": [
    "#### 3.0 Check the first transactions time for stores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8467f745de31df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:04:18.977676Z",
     "start_time": "2025-03-08T07:04:18.592380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the SQL query to get the first transaction date for each store\n",
    "query_store_open_date = \"\"\"\n",
    "WITH store_first_transaction AS (\n",
    "    SELECT\n",
    "        store_id,\n",
    "        MIN(CAST(trans_dt AS DATE)) AS first_transaction_date\n",
    "    FROM df_transactions\n",
    "    GROUP BY store_id\n",
    ")\n",
    "SELECT *\n",
    "FROM store_first_transaction\n",
    "ORDER BY first_transaction_date DESC;\n",
    "\"\"\"\n",
    "df_stores_od = con.execute(query_store_open_date).fetchdf()\n",
    "print(\"Store open dates:\")\n",
    "print(df_stores_od)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544e108e63187e",
   "metadata": {},
   "source": [
    "### 3.1 Overall Store Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4570416dc9362d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T06:07:16.598634Z",
     "start_time": "2025-03-08T06:07:11.924557Z"
    }
   },
   "outputs": [],
   "source": [
    "query_store_perf = \"\"\"\n",
    "WITH all_stores AS (\n",
    "    SELECT DISTINCT store_id \n",
    "    FROM df_transactions\n",
    "),\n",
    "\n",
    "store_performance AS (\n",
    "    SELECT\n",
    "        s.store_id,\n",
    "        ROUND(COALESCE(SUM(t.sales_amt), 0), 2) AS total_revenue,\n",
    "        ROUND(COALESCE(SUM(t.sales_qty), 0), 2) AS total_volume,\n",
    "        COUNT(DISTINCT t.trans_id) AS total_transactions,\n",
    "        COUNT(DISTINCT t.cust_id) AS unique_customers\n",
    "    FROM all_stores s\n",
    "    LEFT JOIN df_transactions t\n",
    "    ON s.store_id = t.store_id\n",
    "    GROUP BY s.store_id\n",
    "),\n",
    "\n",
    "ranked_stores AS (\n",
    "    SELECT *,\n",
    "        RANK() OVER (ORDER BY total_revenue DESC) AS revenue_rank,\n",
    "        RANK() OVER (ORDER BY total_volume DESC) AS volume_rank,\n",
    "        RANK() OVER (ORDER BY total_transactions DESC) AS transaction_rank,\n",
    "        RANK() OVER (ORDER BY unique_customers DESC) AS customer_rank\n",
    "    FROM store_performance\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM ranked_stores\n",
    "ORDER BY revenue_rank;\n",
    "\"\"\"\n",
    "df_store_perf = con.execute(query_store_perf).fetchdf()\n",
    "print(\"All-time store ranking:\")\n",
    "display(df_store_perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82078ddc00eadd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:03:03.260694Z",
     "start_time": "2025-03-08T07:03:03.227998Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(x=df_store_perf['total_revenue'])\n",
    "\n",
    "plt.title(\"Distribution of Total Revenue per Store\", fontsize=14)\n",
    "plt.xlabel(\"Total Revenue\", fontsize=12)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a8a895efeeb79",
   "metadata": {},
   "source": [
    "## 3.3 Understanding the trend of the store performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb28948e4a3de4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T06:06:30.390356Z",
     "start_time": "2025-03-08T06:06:30.368475Z"
    }
   },
   "outputs": [],
   "source": [
    "df_transactions['trans_dt'] = pd.to_datetime(df_transactions['trans_dt'])\n",
    "df_transactions['year_month'] = df_transactions['trans_dt'].dt.to_period('M')\n",
    "\n",
    "# Group by store and month to get monthly sums/counts\n",
    "monthly_store = (\n",
    "    df_transactions\n",
    "    .groupby(['store_id', 'year_month'], as_index=False)\n",
    "    .agg(\n",
    "        total_revenue=('sales_amt', 'sum'),\n",
    "        total_transactions=('trans_id', 'nunique'),\n",
    "        unique_customers=('cust_id', 'nunique')\n",
    "    )\n",
    ")\n",
    "# Calculate average transaction value per store, per month\n",
    "monthly_store['avg_transaction_value'] = (\n",
    "    monthly_store['total_revenue'] / monthly_store['total_transactions']\n",
    ")\n",
    "\n",
    "# Get overall monthly averages across all stores\n",
    "monthly_averages = (\n",
    "    monthly_store\n",
    "    .groupby('year_month', as_index=False)\n",
    "    .agg(\n",
    "        avg_transaction_value=('avg_transaction_value', 'mean'),\n",
    "        avg_revenue_per_store=('total_revenue', 'mean'),\n",
    "        avg_transactions_per_store=('total_transactions', 'mean'),\n",
    "        avg_customer_count=('unique_customers', 'mean')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "display(monthly_averages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91faedc2111f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.975180Z",
     "start_time": "2025-03-08T05:23:36.077689Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_averages['year_month'] = monthly_averages['year_month'].astype(str)\n",
    "\n",
    "# Plot Revenue Trend Over Time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_averages['year_month'], monthly_averages['avg_revenue_per_store'], marker='o', linestyle='-', color='blue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Year-Month\")\n",
    "plt.ylabel(\"Average Revenue Per Store\")\n",
    "plt.title(\"Trend of Average Revenue Per Store Over Time\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0c663ffc94d0f",
   "metadata": {},
   "source": [
    "###According to the Capitalone research data,the average retail return rate is 26.4% for eCommerce and 10.0% for in-store purchases. so stores that have higher than 10% return should be flagged as abnormal.\n",
    "https://capitaloneshopping.com/research/average-retail-return-rate/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436dd5033110e9f6",
   "metadata": {},
   "source": [
    "# Q4. Are there interesting groupings of customers, e.g., most valuable (buy everything at any price) or cherry-pickers (buy mostly on promotions), defined by certain categories (buy baby products or never buy milk), etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec71a06-030d-445b-874f-943feaa318fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0215d-242f-45fa-850b-1622259ee3cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.975678Z",
     "start_time": "2025-03-08T05:17:02.201019Z"
    }
   },
   "source": [
    "### 4.1 Customer Spending Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16087069-d0ef-4a98-bf48-116874adcac5",
   "metadata": {},
   "source": [
    "- Product Category Analysis\n",
    "- Price Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa82f95-ea02-43f5-9b38-457952e73ea1",
   "metadata": {},
   "source": [
    "##### Product Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b9bd9f2849bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique product categories per customer\n",
    "customer_category_diversity = df_combined.groupby('cust_id')['prod_category'].nunique().reset_index()\n",
    "customer_category_diversity.columns = ['cust_id', 'unique_categories']\n",
    "\n",
    "# Unique products per customer\n",
    "customer_product_diversity = df_combined.groupby('cust_id')['prod_id'].nunique().reset_index()\n",
    "customer_product_diversity.columns = ['cust_id', 'unique_products']\n",
    "\n",
    "# Category focused customers versus broad shoppers\n",
    "category_counts = df_combined.groupby(['cust_id', 'prod_category']).size().reset_index(name='category_purchase_count')\n",
    "customer_total_purchases = df_combined.groupby('cust_id').size().reset_index(name='total_purchases')\n",
    "category_concentration = category_counts.merge(customer_total_purchases, on='cust_id')\n",
    "category_concentration['category_percentage'] = category_concentration['category_purchase_count'] / category_concentration['total_purchases']\n",
    "\n",
    "# Top Category per customer\n",
    "top_category_by_customer = category_concentration.sort_values(['cust_id', 'category_percentage'], ascending=[True, False])\n",
    "top_category_by_customer = top_category_by_customer.drop_duplicates('cust_id')\n",
    "top_category_by_customer = top_category_by_customer[['cust_id', 'prod_category', 'category_percentage']]\n",
    "top_category_by_customer.columns = ['cust_id', 'top_category', 'top_category_percentage']\n",
    "\n",
    "# Combining Purchase diversity metrics\n",
    "purchase_diversity = customer_category_diversity.merge(\n",
    "    customer_product_diversity, on='cust_id', how='left'\n",
    ").merge(\n",
    "    top_category_by_customer, on='cust_id', how='left'\n",
    ")\n",
    "# Fill NaN values\n",
    "purchase_diversity = purchase_diversity.fillna(0)\n",
    "display(purchase_diversity.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c36540033a3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prod category based customer segments\n",
    "def categorize_diversity(top_percentage):\n",
    "    if top_percentage >= 0.8:\n",
    "        return \"Top_category_shoppers\"\n",
    "    elif top_percentage >= 0.5:\n",
    "        return \"Category-Focused Shopper\"\n",
    "    elif top_percentage >= 0.3:\n",
    "        return \"Balanced Shopper\"\n",
    "    else:\n",
    "        return \"Diverse Shopper\"\n",
    "\n",
    "purchase_diversity['category_segment'] = purchase_diversity['top_category_percentage'].apply(categorize_diversity)\n",
    "\n",
    "# Counting customers in each segment\n",
    "df_shoppers = purchase_diversity['category_segment'].value_counts()\n",
    "display(df_shoppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd427cf9-0a39-4364-9840-b9da45e67b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of categories by segment\n",
    "category_by_segment = purchase_diversity.groupby('category_segment')['unique_categories'].mean()\n",
    "display(category_by_segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06f435-47b5-4dca-8ea3-7b685bf5f318",
   "metadata": {},
   "source": [
    "##### Price Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e310086fa7d5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average price paid per product by each customer: How much each customer spends per product on average.\n",
    "customer_price = stratified_sample_df.groupby('cust_id')['sales_amt'].mean().reset_index()\n",
    "customer_price.columns = ['cust_id', 'avg_price_paid']\n",
    "\n",
    "# Calculate overall average price for each product. This sets a baseline \"market price\" for each product.\n",
    "product_avg_price = stratified_sample_df.groupby('prod_id')['sales_amt'].mean().reset_index()\n",
    "product_avg_price.columns = ['prod_id', 'product_avg_price']\n",
    "\n",
    "# Join average product price to transaction data\n",
    "price_comparison = stratified_sample_df.merge(product_avg_price, on='prod_id')\n",
    "\n",
    "# Price ratio for each transaction (customer price / average price). \n",
    "# Relative to the average price of the product, how much does a customer spend.\n",
    "# >1.0 = less price-sensitive customer, 1.0 = avg prod price and <1.0 = price-sensitive cusotmer\n",
    "price_comparison['price_ratio'] = price_comparison['sales_amt'] / price_comparison['product_avg_price']\n",
    "\n",
    "# Average price ratio by customer\n",
    "customer_price_sensitivity = price_comparison.groupby('cust_id')['price_ratio'].mean().reset_index()\n",
    "customer_price_sensitivity.columns = ['cust_id', 'price_sensitivity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fa4a210173a4d",
   "metadata": {},
   "source": [
    "# Q5. Other than product categories and sub-categories, are there other product groupings, e.g., Key Value Items (KVI) and Key Value Categories (KVC), traffic drivers, always promoted versus seldom/never promoted, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f61e5d7b8a563c",
   "metadata": {},
   "source": [
    "## 5.1 Analyze Product Groupings --- Key Value Items (KVI) & Key Value Categories (KVC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a342e296f64923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.975930Z",
     "start_time": "2025-03-06T16:45:06.591183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate sales quantity by product subcategory\n",
    "top_kvi_products = df_combined.groupby(\"prod_subcategory\")[\"sales_qty\"].sum().nlargest(10)\n",
    "\n",
    "# Plot Key Value Items (KVI) by subcategory\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_kvi_products.index, y=top_kvi_products.values, palette=\"coolwarm\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top 10 Key Value Product Subcategories\")\n",
    "plt.xlabel(\"Product Subcategory\")\n",
    "plt.ylabel(\"Total Sales Quantity\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed34bd3e0ed7d1d8",
   "metadata": {},
   "source": [
    "## 5.2 Analyze Product Groupings --- Traffic Drivers (Products Frequently Bought Alone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6f2080e312f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate transaction counts by product subcategory\n",
    "traffic_drivers = df_combined[df_combined.duplicated(subset=[\"trans_id\"], keep=False) == False]\n",
    "top_traffic_drivers = traffic_drivers.groupby(\"prod_subcategory\")[\"prod_id\"].count().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Plot Traffic Driver Products by Subcategory\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_traffic_drivers.index, y=top_traffic_drivers.values, palette=\"Blues_r\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top 10 Traffic Driver Product Subcategories\")\n",
    "plt.xlabel(\"Product Subcategory\")\n",
    "plt.ylabel(\"Total Transactions\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c15f8cf4722c0",
   "metadata": {},
   "source": [
    "## 5.3 Analyze Product Groupings --- Always Promoted vs. Seldom/Never Promoted Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c840e7962f56417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate promotion counts by product subcategory\n",
    "promoted_products = df_combined[df_combined[\"sales_amt\"] < df_combined[\"sales_amt\"].mean()]\n",
    "promoted_counts = promoted_products.groupby(\"prod_subcategory\")[\"prod_id\"].count().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Plot Promoted Items with correct x and y axes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=promoted_counts.index, y=promoted_counts.values, palette=\"Greens_r\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top 10 Frequently Promoted Product Subcategories\")\n",
    "plt.xlabel(\"Product Subcategory\")\n",
    "plt.ylabel(\"Total Number of Promotions\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36ee8249177877",
   "metadata": {},
   "source": [
    "## 5.4 Analyze Product Groupings --- Loss Leaders vs. High-Margin Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3211d6a93c0a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify key drivers for most transactions (most purchased products, most revenue-generating stores)\n",
    "query_key_drivers = \"\"\"\n",
    "SELECT prod_id, COUNT(trans_id) AS transaction_count, SUM(sales_amt) AS total_revenue\n",
    "FROM `msba-emory.isom676_machine_learning.transactions`\n",
    "GROUP BY prod_id\n",
    "ORDER BY transaction_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Compare product prices over time (current vs. previous)\n",
    "query_price_comparison = \"\"\"\n",
    "SELECT prod_id, trans_dt, sales_amt / sales_qty AS unit_price\n",
    "FROM `msba-emory.isom676_machine_learning.transactions`\n",
    "WHERE sales_qty > 0 AND trans_dt BETWEEN '2019-01-01' AND '2020-12-31'\n",
    "ORDER BY prod_id, trans_dt\n",
    "\"\"\"\n",
    "\n",
    "# Monthly transaction trends for 2020\n",
    "query_monthly_trends = \"\"\"\n",
    "SELECT EXTRACT(MONTH FROM trans_dt) AS month, COUNT(trans_id) AS transaction_count, SUM(sales_amt) AS total_revenue\n",
    "FROM `msba-emory.isom676_machine_learning.transactions`\n",
    "WHERE trans_dt BETWEEN '2020-01-01' AND '2020-12-31'\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\"\n",
    "\n",
    "# Check the effect of promotions\n",
    "query_promotions_effect = \"\"\"\n",
    "SELECT prod_id, COUNT(trans_id) AS total_transactions,\n",
    "       SUM(sales_amt) AS total_revenue,\n",
    "       AVG(sales_amt / sales_qty) AS avg_price\n",
    "FROM `msba-emory.isom676_machine_learning.transactions`\n",
    "WHERE sales_amt < 0  -- Assuming negative sales_amt indicates promotions/discounts\n",
    "GROUP BY prod_id\n",
    "ORDER BY total_transactions DESC\n",
    "LIMIT 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f27a7dbb1f2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing the queries\n",
    "query_results = {}\n",
    "queries = {\n",
    "    \"Key Drivers\": query_key_drivers,\n",
    "    \"Price Comparison\": query_price_comparison,\n",
    "    \"Monthly Trends\": query_monthly_trends,\n",
    "    \"Promotions Effect\": query_promotions_effect\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8602652ea67b2",
   "metadata": {},
   "source": [
    "## 5.5 Prices between 2020 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686983b18a83fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query for DuckDB\n",
    "query_price_comparison = \"\"\"\n",
    "SELECT \n",
    "    prod_id,\n",
    "    EXTRACT(YEAR FROM trans_dt) AS year,\n",
    "    AVG(sales_amt / NULLIF(sales_qty, 0)) AS avg_unit_price\n",
    "FROM read_parquet('C:/Users/Jiyuan Xin/Downloads/ACSEData/ACSEData/transactions.parquet')\n",
    "WHERE trans_dt BETWEEN '2019-01-01' AND '2020-12-31'\n",
    "GROUP BY prod_id, year\n",
    "ORDER BY prod_id, year\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query using DuckDB\n",
    "df_price_comparison = con.execute(query_price_comparison).fetchdf()\n",
    "\n",
    "# Pivot table to compare price changes between 2019 and 2020\n",
    "df_price_pivot = df_price_comparison.pivot(index=\"prod_id\", columns=\"year\", values=\"avg_unit_price\").reset_index()\n",
    "df_price_pivot.columns = [\"Product ID\", \"2019 Avg Price\", \"2020 Avg Price\"]\n",
    "\n",
    "# Calculate price difference and percentage change\n",
    "df_price_pivot[\"Price Change\"] = df_price_pivot[\"2020 Avg Price\"] - df_price_pivot[\"2019 Avg Price\"]\n",
    "df_price_pivot[\"% Change\"] = (df_price_pivot[\"Price Change\"] / df_price_pivot[\"2019 Avg Price\"]) * 100\n",
    "\n",
    "# Display the results\n",
    "print(df_price_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e9c68fba26ed5",
   "metadata": {},
   "source": [
    "Monthly Level for 2020 (Most recent year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efecc7a4319cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get monthly transaction trends for 2020\n",
    "query_monthly_trends = \"\"\"\n",
    "SELECT\n",
    "    EXTRACT(MONTH FROM trans_dt) AS month,\n",
    "    COUNT(trans_id) AS transaction_count,\n",
    "    SUM(sales_amt) AS total_revenue,\n",
    "    AVG(sales_amt / NULLIF(sales_qty, 0)) AS avg_unit_price\n",
    "FROM read_parquet('C:/Users/Jiyuan Xin/Downloads/ACSEData/ACSEData/transactions.parquet')\n",
    "WHERE trans_dt BETWEEN '2020-01-01' AND '2020-12-31'\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query using DuckDB\n",
    "df_monthly_trends = duckdb.query(query_monthly_trends).to_df()\n",
    "\n",
    "# Rename the month column for better readability\n",
    "df_monthly_trends.rename(columns={\"month\": \"Month\", \"transaction_count\": \"Total Transactions\", \"total_revenue\": \"Total Revenue\", \"avg_unit_price\": \"Avg Unit Price\"}, inplace=True)\n",
    "\n",
    "# Display the results\n",
    "print(df_monthly_trends)  # Print the DataFrame to console\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f033f75ad17baf8",
   "metadata": {},
   "source": [
    "## 5.6 Always promoted Vs. Seldom/Never Promoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edad52b35ca1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to analyze always promoted vs seldom/never promoted products in 2020\n",
    "query_promotion_analysis = \"\"\"\n",
    "WITH PromotionData AS (\n",
    "    SELECT\n",
    "        prod_id,\n",
    "        COUNT(CASE WHEN sales_amt < 0 THEN trans_id END) AS promo_transactions,\n",
    "        COUNT(trans_id) AS total_transactions,\n",
    "        SUM(CASE WHEN sales_amt < 0 THEN sales_amt ELSE 0 END) AS promo_sales,\n",
    "        SUM(sales_amt) AS total_sales\n",
    "    FROM read_parquet('C:/Users/Jiyuan Xin/Downloads/ACSEData/ACSEData/transactions.parquet')\n",
    "    WHERE trans_dt BETWEEN '2020-01-01' AND '2020-12-31'\n",
    "    GROUP BY prod_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    prod_id,\n",
    "    total_transactions,\n",
    "    promo_transactions,\n",
    "    (promo_transactions * 1.0 / total_transactions) AS promo_ratio,\n",
    "    promo_sales,\n",
    "    total_sales\n",
    "FROM PromotionData\n",
    "ORDER BY promo_ratio DESC\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query using DuckDB\n",
    "df_promotion_analysis = duckdb.query(query_promotion_analysis).to_df()\n",
    "\n",
    "# Categorize products into \"Always Promoted\" vs. \"Seldom/Never Promoted\"\n",
    "df_promotion_analysis[\"Promotion Category\"] = df_promotion_analysis[\"promo_ratio\"].apply(\n",
    "    lambda x: \"Always Promoted\" if x > 0.75 else \"Seldom/Never Promoted\"\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(df_promotion_analysis)  # Print the DataFrame to console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d0c32389ca5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data for visualization (since I cannot run BigQuery here)\n",
    "sample_data = {\n",
    "    \"Promotion Category\": [\"Always Promoted\", \"Seldom/Never Promoted\"],\n",
    "    \"Number of Products\": [250, 750]  # Example counts\n",
    "}\n",
    "\n",
    "# Create a bar chart to show the number of products in each category\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(sample_data[\"Promotion Category\"], sample_data[\"Number of Products\"], alpha=0.7)\n",
    "plt.xlabel(\"Promotion Category\")\n",
    "plt.ylabel(\"Number of Products\")\n",
    "plt.title(\"Comparison of Always Promoted vs. Seldom/Never Promoted Products (2020)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac71a2e4e5fec04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4fc305d3b0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SQL query to compute yearly discount rates for 2017-2020\n",
    "query_discount_rate = \"\"\"\n",
    "WITH YearlyDiscount AS (\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM trans_dt) AS year,\n",
    "        SUM(CASE WHEN sales_amt < 0 THEN sales_amt ELSE 0 END) / SUM(ABS(sales_amt)) AS discount_rate\n",
    "    FROM read_parquet('C:/Users/Jiyuan Xin/Downloads/ACSEData/ACSEData/transactions.parquet')\n",
    "    WHERE EXTRACT(YEAR FROM trans_dt) BETWEEN 2017 AND 2020\n",
    "    GROUP BY year\n",
    ")\n",
    "\n",
    "SELECT * FROM YearlyDiscount ORDER BY year;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query using DuckDB\n",
    "df_discount_rate = duckdb.query(query_discount_rate).to_df()\n",
    "\n",
    "# Display the results\n",
    "display(df_discount_rate)  # Display the DataFrame\n",
    "\n",
    "# Visualization of discount trends over the years\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(df_discount_rate[\"year\"], df_discount_rate[\"discount_rate\"] * 100, marker=\"o\", linestyle=\"-\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Discount Rate (%)\")\n",
    "plt.title(\"Yearly Discount Rates (2017-2020)\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62718d63d64c4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get total sales quantity per product from 2017 to 2020\n",
    "transactions_query = f\"\"\"\n",
    "SELECT \n",
    "    prod_id, \n",
    "    SUM(sales_qty) AS total_sales\n",
    "FROM read_parquet('C:/Users/Jiyuan Xin/Downloads/ACSEData/ACSEData/transactions.parquet')\n",
    "WHERE trans_dt BETWEEN '2017-01-01' AND '2020-12-31'\n",
    "GROUP BY prod_id\n",
    "ORDER BY total_sales DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "top_promoted_products = con.execute(transactions_query).fetchdf()\n",
    "\n",
    "# Load product descriptions from the products table\n",
    "products_query = f\"\"\"\n",
    "SELECT \n",
    "    prod_id, \n",
    "    prod_desc\n",
    "FROM read_parquet('{products_path}')\n",
    "\"\"\"\n",
    "products_df = con.execute(products_query).fetchdf()\n",
    "\n",
    "# Merge product descriptions\n",
    "top_promoted_products = top_promoted_products.merge(products_df, on=\"prod_id\", how=\"left\")\n",
    "\n",
    "# Display the result\n",
    "print(top_promoted_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4359926d9587678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(top_10_promo_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff68eda96c1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file paths\n",
    "transactions_path = \"C:/Users/Jiyuan Xin/Downloads/ACSEData/ACSEData/transactions.parquet\"\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "# Corrected SQL Query\n",
    "query_top_promo_percentage = f\"\"\"\n",
    "WITH ProductYearlyAvg AS (\n",
    "    -- Calculate the average yearly price per product\n",
    "    SELECT\n",
    "        prod_id,\n",
    "        strftime('%Y', trans_dt) AS year,\n",
    "        AVG(CASE WHEN sales_qty > 0 THEN sales_amt / NULLIF(sales_qty, 0) ELSE NULL END) AS avg_price\n",
    "    FROM read_parquet('{transactions_path}')\n",
    "    WHERE sales_qty > 0\n",
    "    GROUP BY prod_id, strftime('%Y', trans_dt)  --  Group by the correct expression\n",
    "),\n",
    "PromoTransactions AS (\n",
    "    -- Count total transactions and promotional transactions where price < yearly avg\n",
    "    SELECT\n",
    "        t.prod_id,\n",
    "        strftime('%Y', t.trans_dt) AS year,\n",
    "        COUNT(t.trans_id) AS total_transactions,\n",
    "        COUNT(CASE WHEN (t.sales_amt / NULLIF(t.sales_qty, 0)) < p.avg_price THEN t.trans_id END) AS total_promo_transactions\n",
    "    FROM read_parquet('{transactions_path}') t\n",
    "    JOIN ProductYearlyAvg p\n",
    "        ON t.prod_id = p.prod_id AND strftime('%Y', t.trans_dt) = p.year  --  Corrected column reference\n",
    "    WHERE t.sales_qty > 0\n",
    "    GROUP BY t.prod_id, strftime('%Y', t.trans_dt)  --  Group by original expression\n",
    ")\n",
    "-- Aggregate over four years and compute promo percentage\n",
    "SELECT\n",
    "    prod_id,\n",
    "    SUM(total_promo_transactions) AS total_promo_transactions,\n",
    "    SUM(total_transactions) AS total_transactions,\n",
    "    (SUM(total_promo_transactions) * 1.0 / NULLIF(SUM(total_transactions), 0)) * 100 AS promo_percentage\n",
    "FROM PromoTransactions\n",
    "GROUP BY prod_id\n",
    "ORDER BY promo_percentage DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch results\n",
    "top_promo_products_df = con.execute(query_top_promo_percentage).fetchdf()\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "display(top_promo_products_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8c8ed2de1676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "transactions_path = \"C:/Users/Jiyuan Xin/Downloads/ACSEData/ACSEData/transactions.parquet\"\n",
    "products_path = \"C:/Users/Jiyuan Xin/Downloads/ACSEData/ACSEData/products.parquet\"\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "# Corrected SQL Query\n",
    "query_promo_distribution = f\"\"\"\n",
    "WITH ProductYearlyAvg AS (\n",
    "    -- Calculate the average yearly price for each product\n",
    "    SELECT\n",
    "        prod_id,\n",
    "        strftime('%Y', trans_dt) AS year,\n",
    "        AVG(CASE WHEN sales_qty > 0 THEN sales_amt / NULLIF(sales_qty, 0) ELSE NULL END) AS avg_price\n",
    "    FROM read_parquet('{transactions_path}')\n",
    "    WHERE sales_qty > 0\n",
    "    GROUP BY prod_id, strftime('%Y', trans_dt)\n",
    "),\n",
    "PromoTransactions AS (\n",
    "    -- Count total transactions and promotional transactions where price < yearly avg\n",
    "    SELECT\n",
    "        t.prod_id,\n",
    "        strftime('%Y', t.trans_dt) AS year,\n",
    "        COUNT(t.trans_id) AS total_transactions,\n",
    "        COUNT(CASE WHEN (t.sales_amt / NULLIF(t.sales_qty, 0)) < p.avg_price THEN t.trans_id END) AS promo_transactions\n",
    "    FROM read_parquet('{transactions_path}') t\n",
    "    JOIN ProductYearlyAvg p\n",
    "        ON t.prod_id = p.prod_id AND strftime('%Y', t.trans_dt) = p.year\n",
    "    WHERE t.sales_qty > 0\n",
    "    GROUP BY t.prod_id, strftime('%Y', t.trans_dt)\n",
    ")\n",
    "-- Aggregate by product category and subcategory\n",
    "SELECT\n",
    "    pr.prod_category,\n",
    "    pr.prod_subcategory,\n",
    "    SUM(pt.promo_transactions) AS total_promo_transactions,\n",
    "    SUM(pt.total_transactions) AS total_transactions,\n",
    "    (SUM(pt.promo_transactions) * 1.0 / NULLIF(SUM(pt.total_transactions), 0)) * 100 AS promo_percentage\n",
    "FROM PromoTransactions pt\n",
    "JOIN read_parquet('{products_path}') pr ON pt.prod_id = pr.prod_id\n",
    "GROUP BY pr.prod_category, pr.prod_subcategory\n",
    "ORDER BY total_promo_transactions DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch results\n",
    "df_promo_distribution = con.execute(query_promo_distribution).fetchdf()\n",
    "\n",
    "# Display the top 10 rows\n",
    "from IPython.display import display\n",
    "\n",
    "display(top_promo_products_df)\n",
    "\n",
    "# Sort data by Total Promo Transactions\n",
    "df_sorted_promo_transactions = df_promo_distribution.sort_values(by=\"total_promo_transactions\", ascending=False)\n",
    "\n",
    "# First plot: Total Promo Transactions by Product Category (sorted)\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.barplot(data=df_sorted_promo_transactions, x=\"prod_category\", y=\"total_promo_transactions\")\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=6)\n",
    "plt.xlabel(\"Product Category\")\n",
    "plt.ylabel(\"Total Promo Transactions\")\n",
    "plt.title(\"Total Promo Transactions by Product Category (Sorted)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Sort data by Promotion Percentage\n",
    "df_sorted_promo_percentage = df_promo_distribution.sort_values(by=\"promo_percentage\", ascending=False)\n",
    "\n",
    "# Second plot: Promotion Percentage by Product Category (sorted)\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.barplot(data=df_sorted_promo_percentage, x=\"prod_category\", y=\"promo_percentage\")\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=6)\n",
    "plt.xlabel(\"Product Category\")\n",
    "plt.ylabel(\"Promotion Percentage (%)\")\n",
    "plt.title(\"Promotion Percentage by Product Category (Sorted)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8b74da3c705bf",
   "metadata": {},
   "source": [
    "# Q6. Are there natural groupings of stores, e.g., stores frequented by cherry-pickers versus stores visited by most loyal customers?## 6.1 Group by products specialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e057743c2152753",
   "metadata": {},
   "source": [
    "## 6.1 Group by Store Revenue  (high, low, mid performance stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da3212f6eaf7b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:15:34.664133Z",
     "start_time": "2025-03-08T07:15:34.563285Z"
    }
   },
   "outputs": [],
   "source": [
    "query_store_revenue = \"\"\"\n",
    "SELECT\n",
    "    store_id,\n",
    "    ROUND(SUM(sales_amt), 2) AS total_revenue,\n",
    "    CASE\n",
    "        WHEN ROUND(SUM(sales_amt), 2)  > 8000000 THEN 'High-performance'\n",
    "        WHEN ROUND(SUM(sales_amt), 2)  < 400000 THEN 'Low-performance'\n",
    "        ELSE 'Medium-performance'\n",
    "    END AS store_performance\n",
    "FROM df_transactions\n",
    "GROUP BY store_id;\n",
    "\"\"\"\n",
    "df_store_rev = con.execute(query_store_revenue).fetchdf()\n",
    "print(\"Stores grouped by traffic level:\")\n",
    "display(df_store_rev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff85fde281f4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:16:28.872428Z",
     "start_time": "2025-03-08T07:16:28.868081Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the count of stores per performance category\n",
    "performance_counts = df_store_rev['store_performance'].value_counts().reset_index()\n",
    "performance_counts.columns = ['store_performance', 'count']\n",
    "\n",
    "# Calculate the percentage for each performance category\n",
    "performance_counts['percentage'] = (performance_counts['count'] / len(df_store_rev)) * 100\n",
    "\n",
    "print(\"Store Performance Distribution (Count and Percentage):\")\n",
    "display(performance_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e458d895e3bab0",
   "metadata": {},
   "source": [
    "### 6.1.1 Checking Store traffics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43243aea08b57313",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_store_traffic = \"\"\"\n",
    "SELECT\n",
    "    store_id,\n",
    "    COUNT(DISTINCT trans_id) AS total_transactions,\n",
    "    COUNT(DISTINCT cust_id) AS unique_customers,\n",
    "    CASE\n",
    "        WHEN COUNT(DISTINCT trans_id) > 1000000 THEN 'High-Traffic'\n",
    "        WHEN COUNT(DISTINCT trans_id) < 30000 THEN 'Low-Traffic'\n",
    "        ELSE 'Medium-Traffic'\n",
    "    END AS store_traffic_category\n",
    "FROM df_transactions\n",
    "GROUP BY store_id;\n",
    "\"\"\"\n",
    "df_store_traffic = con.execute(query_store_traffic).fetchdf()\n",
    "print(\"Stores grouped by traffic level:\")\n",
    "display(df_store_traffic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb735227f0f997e",
   "metadata": {},
   "source": [
    "### 6.1.2 Checking Low performance store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cece3eb18f84b76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:29:48.233503Z",
     "start_time": "2025-03-08T07:29:48.163885Z"
    }
   },
   "outputs": [],
   "source": [
    "query_low_perf_products = \"\"\"\n",
    "WITH low_perf_stores AS (\n",
    "    SELECT store_id\n",
    "    FROM df_store_rev\n",
    "    WHERE total_revenue < 400000  -- Low-performing stores threshold\n",
    "),\n",
    "\n",
    "low_perf_product_sales AS (\n",
    "    SELECT \n",
    "        t.store_id,\n",
    "        p.prod_category,\n",
    "        p.prod_subcategory,\n",
    "        SUM(t.sales_amt) AS total_sales,\n",
    "        COUNT(DISTINCT t.trans_id) AS total_transactions,\n",
    "        COUNT(DISTINCT t.cust_id) AS unique_customers\n",
    "    FROM df_transactions t\n",
    "    JOIN df_products p\n",
    "    ON t.prod_id = p.prod_id\n",
    "    WHERE t.store_id IN (SELECT store_id FROM low_perf_stores)\n",
    "    GROUP BY t.store_id, p.prod_category, p.prod_subcategory\n",
    "),\n",
    "\n",
    "category_summary AS (\n",
    "    SELECT \n",
    "        prod_category,\n",
    "        prod_subcategory,\n",
    "        SUM(total_sales) AS total_sales,\n",
    "        SUM(total_transactions) AS total_transactions,\n",
    "        SUM(unique_customers) AS total_customers,\n",
    "        COUNT(DISTINCT store_id) AS num_stores\n",
    "    FROM low_perf_product_sales\n",
    "    GROUP BY prod_category, prod_subcategory\n",
    "    ORDER BY total_sales DESC\n",
    ")\n",
    "\n",
    "SELECT * FROM category_summary;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "df_low_perf_categories = con.execute(query_low_perf_products).fetchdf()\n",
    "display(\"Low-Performing Store Product Categories\",df_low_perf_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafaa5abdb871833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:32:10.316050Z",
     "start_time": "2025-03-08T07:32:05.729234Z"
    }
   },
   "outputs": [],
   "source": [
    "query_high_perf_products = \"\"\"\n",
    "WITH high_perf_stores AS (\n",
    "    SELECT store_id\n",
    "    FROM df_store_rev\n",
    "    WHERE total_revenue > 8000000  -- Low-performing stores threshold\n",
    "),\n",
    "\n",
    "high_perf_product_sales AS (\n",
    "    SELECT \n",
    "        t.store_id,\n",
    "        p.prod_category,\n",
    "        p.prod_subcategory,\n",
    "        SUM(t.sales_amt) AS total_sales,\n",
    "        COUNT(DISTINCT t.trans_id) AS total_transactions,\n",
    "        COUNT(DISTINCT t.cust_id) AS unique_customers\n",
    "    FROM df_transactions t\n",
    "    JOIN df_products p\n",
    "    ON t.prod_id = p.prod_id\n",
    "    WHERE t.store_id IN (SELECT store_id FROM high_perf_stores)\n",
    "    GROUP BY t.store_id, p.prod_category, p.prod_subcategory\n",
    "),\n",
    "\n",
    "category_summary AS (\n",
    "    SELECT \n",
    "        prod_category,\n",
    "        prod_subcategory,\n",
    "        SUM(total_sales) AS total_sales,\n",
    "        SUM(total_transactions) AS total_transactions,\n",
    "        SUM(unique_customers) AS total_customers,\n",
    "        COUNT(DISTINCT store_id) AS num_stores\n",
    "    FROM high_perf_product_sales\n",
    "    GROUP BY prod_category, prod_subcategory\n",
    "    ORDER BY total_sales DESC\n",
    ")\n",
    "\n",
    "SELECT * FROM category_summary\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "df_high_perf_categories = con.execute(query_high_perf_products).fetchdf()\n",
    "display(\"high-Performing Store Product Categories\",df_high_perf_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b89b61afce10c5",
   "metadata": {},
   "source": [
    "### 6.1.3 Understanding store 8540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7fd5908dcc0d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:38:18.277328Z",
     "start_time": "2025-03-08T07:38:12.987552Z"
    }
   },
   "outputs": [],
   "source": [
    "query_store_8540 = \"\"\"\n",
    "SELECT *\n",
    "FROM df_combined\n",
    "WHERE store_id = 8540\n",
    "ORDER BY trans_dt;\n",
    "\"\"\"\n",
    "\n",
    "df_store_8540 = con.execute(query_store_8540).fetchdf()\n",
    "print(\"Transactions for Store 8540:\")\n",
    "display(df_store_8540)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef81cdf7d3dcc942",
   "metadata": {},
   "source": [
    "### 6.1.4 Group by products specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb378a8b1cd18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_store_prod = \"\"\"\n",
    "WITH store_product_mix AS (\n",
    "    SELECT \n",
    "        t.store_id, \n",
    "        p.prod_category,  \n",
    "        SUM(t.sales_amt) AS category_revenue\n",
    "    FROM df_transactions AS t\n",
    "    JOIN df_products AS p\n",
    "      ON t.prod_id = p.prod_id\n",
    "    GROUP BY t.store_id, p.prod_category\n",
    "),\n",
    "store_total_revenue AS (\n",
    "    SELECT \n",
    "        store_id, \n",
    "        SUM(category_revenue) AS total_store_revenue\n",
    "    FROM store_product_mix\n",
    "    GROUP BY store_id\n",
    "),\n",
    "dominant_category AS (\n",
    "    SELECT \n",
    "        spm.store_id, \n",
    "        spm.prod_category,\n",
    "        spm.category_revenue,\n",
    "        str.total_store_revenue,\n",
    "        (spm.category_revenue * 100.0 / str.total_store_revenue) AS revenue_percentage,\n",
    "        RANK() OVER (PARTITION BY spm.store_id ORDER BY spm.category_revenue DESC) AS category_rank\n",
    "    FROM store_product_mix spm\n",
    "    JOIN store_total_revenue str\n",
    "      ON spm.store_id = str.store_id\n",
    ")\n",
    "SELECT \n",
    "    store_id, \n",
    "    prod_category AS dominant_category, \n",
    "    category_revenue, \n",
    "    total_store_revenue, \n",
    "    revenue_percentage\n",
    "FROM dominant_category\n",
    "WHERE category_rank = 1;\n",
    "\n",
    "\"\"\"\n",
    "df_store_prod = con.execute(query_store_prod).fetchdf()\n",
    "print(\"Stores grouped by dominant product category:\")\n",
    "display(df_store_prod)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db53074715e01ac",
   "metadata": {},
   "source": [
    "### 6.1.5 Checking coupon usage percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b98e351af5ae74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T17:17:52.828684Z",
     "start_time": "2025-03-08T17:17:51.512041Z"
    }
   },
   "outputs": [],
   "source": [
    "query_coupon_percentage_all_stores = \"\"\"\n",
    "WITH store_transactions AS (\n",
    "    SELECT \n",
    "        store_id,\n",
    "        trans_id,\n",
    "        sales_amt,\n",
    "        prod_category\n",
    "    FROM df_combined\n",
    "),\n",
    "\n",
    "coupon_usage AS (\n",
    "    SELECT \n",
    "        store_id,\n",
    "        COUNT(trans_id) AS coupon_count,\n",
    "        ROUND(SUM(sales_amt), 2) AS coupon_sales  -- Aggregate sales amount for coupon transactions\n",
    "    FROM store_transactions\n",
    "    WHERE LOWER(prod_category) LIKE '%coupon%'  -- Identify coupon-related transactions\n",
    "    GROUP BY store_id\n",
    "),\n",
    "\n",
    "total_transactions AS (\n",
    "    SELECT \n",
    "        store_id,\n",
    "        COUNT(trans_id) AS total_count,\n",
    "        ROUND(SUM(sales_amt), 2) AS total_sales  -- Aggregate total sales per store\n",
    "    FROM store_transactions\n",
    "    GROUP BY store_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    t.store_id,\n",
    "    t.total_count,\n",
    "    t.total_sales,  -- Total sales amount per store\n",
    "    COALESCE(c.coupon_count, 0) AS coupon_count, \n",
    "    COALESCE(c.coupon_sales, 0) AS coupon_sales,  -- Total sales amount from coupons\n",
    "    CONCAT(ROUND((COALESCE(c.coupon_count, 0) * 100.0) / NULLIF(t.total_count, 0), 2), ' %') AS coupon_usage_percentage,\n",
    "    CONCAT(ROUND((COALESCE(c.coupon_sales, 0) * 100.0) / NULLIF(t.total_sales, 0), 2), ' %') AS coupon_sales_percentage\n",
    "FROM total_transactions t\n",
    "LEFT JOIN coupon_usage c ON t.store_id = c.store_id\n",
    "ORDER BY CAST(REPLACE(coupon_usage_percentage, ' %', '') AS FLOAT) DESC;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_coupon_stats_all_stores = con.execute(query_coupon_percentage_all_stores).fetchdf()\n",
    "\n",
    "# Display the coupon usage percentage for all stores\n",
    "print(\"Coupon Usage Percentage for All Stores:\")\n",
    "display(df_coupon_stats_all_stores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeed5cbd704995c",
   "metadata": {},
   "source": [
    "## 6.2 Group buy Customer type (cherry pickers and loyal customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54278d054805c6fe",
   "metadata": {},
   "source": [
    "### 6.2.1 cherry pickers \n",
    "Any customer whose discounted sales meet or exceed that threshold (i.e., they fall in the top 20% for discounted sales) is considered a cherry picker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5996d66771200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:28:14.976656Z",
     "start_time": "2025-03-06T16:46:16.938795Z"
    }
   },
   "outputs": [],
   "source": [
    "query_store_customer_cp = \"\"\"\n",
    "WITH customer_metrics AS (\n",
    "    SELECT\n",
    "        t.cust_id,\n",
    "        SUM(CASE\n",
    "            WHEN (t.sales_amt / NULLIF(t.sales_qty, 0)) < p.prod_uom_value\n",
    "            THEN t.sales_qty\n",
    "            ELSE 0\n",
    "        END) AS discounted_sales\n",
    "    FROM df_transactions t\n",
    "    JOIN df_products p ON t.prod_id = p.prod_id\n",
    "    GROUP BY t.cust_id\n",
    "),\n",
    "cherry_picker_threshold AS (\n",
    "    SELECT\n",
    "        approx_quantile(discounted_sales, 0.8) AS top_20_cherry\n",
    "    FROM customer_metrics\n",
    "),\n",
    "cherry_picker_customers AS (\n",
    "    SELECT DISTINCT cm.cust_id\n",
    "    FROM customer_metrics cm\n",
    "    JOIN cherry_picker_threshold cpt ON cm.discounted_sales >= cpt.top_20_cherry\n",
    "),\n",
    "store_metrics AS (\n",
    "    SELECT\n",
    "        t.store_id,\n",
    "        COUNT(DISTINCT t.cust_id) AS unique_customers,\n",
    "        COUNT(DISTINCT CASE WHEN cpc.cust_id IS NOT NULL THEN t.cust_id END) AS cherry_picker_customers,\n",
    "        ROUND(COUNT(DISTINCT CASE WHEN cpc.cust_id IS NOT NULL THEN t.cust_id END)\n",
    "              / NULLIF(COUNT(DISTINCT t.cust_id), 0) * 100, 2) AS cherry_picker_percentage\n",
    "    FROM df_transactions t\n",
    "    LEFT JOIN cherry_picker_customers cpc ON t.cust_id = cpc.cust_id\n",
    "    GROUP BY t.store_id\n",
    ")\n",
    "SELECT\n",
    "    store_id,\n",
    "    unique_customers,\n",
    "    cherry_picker_customers,\n",
    "    cherry_picker_percentage,\n",
    "    CASE\n",
    "        WHEN cherry_picker_percentage > 50 THEN 'Cherry-Picker Dominant Store'\n",
    "        ELSE 'Not a Cherry-Picker Dominant Store'\n",
    "    END AS store_customer_category\n",
    "FROM store_metrics\n",
    "ORDER BY cherry_picker_percentage DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query in DuckDB and fetch the result as a DataFrame\n",
    "df_store_customer_cp = con.execute(query_store_customer_cp).fetchdf()\n",
    "\n",
    "# Display the results\n",
    "print(\"Stores grouped by cherry picker behavior:\")\n",
    "display(df_store_customer_cp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b448d3fdeb47f",
   "metadata": {},
   "source": [
    "### 6.2.2 Loyal Customer\n",
    "Any customer whose id starts with 1# (membership identification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1052a833688833e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:01:07.124298Z",
     "start_time": "2025-03-08T18:01:04.902267Z"
    }
   },
   "outputs": [],
   "source": [
    "query_store_customer_retention = \"\"\"\n",
    "WITH customer_purchases AS (\n",
    "    SELECT\n",
    "        cust_id,\n",
    "        store_id,\n",
    "        EXTRACT(YEAR FROM trans_dt) AS year,\n",
    "        COUNT(*) AS transaction_count, -- Count total transactions per customer per year\n",
    "        CASE \n",
    "            WHEN CAST(cust_id AS VARCHAR) LIKE '1%' THEN 1  -- Membership ID pattern\n",
    "            ELSE 0\n",
    "        END AS is_member\n",
    "    FROM df_transactions\n",
    "    GROUP BY cust_id, store_id, year\n",
    "),\n",
    "\n",
    "multi_year_customers AS (\n",
    "    SELECT\n",
    "        cust_id,\n",
    "        store_id,\n",
    "        COUNT(DISTINCT year) AS active_years, -- Count distinct years customer made a purchase\n",
    "        SUM(transaction_count) AS total_transactions, -- Total transactions across years\n",
    "        MAX(is_member) AS is_member -- Ensure membership status is retained\n",
    "    FROM customer_purchases\n",
    "    GROUP BY cust_id, store_id\n",
    "),\n",
    "\n",
    "customer_retention AS (\n",
    "    SELECT\n",
    "        store_id,\n",
    "        COUNT(DISTINCT cust_id) AS total_customers,\n",
    "        COUNT(DISTINCT CASE WHEN is_member = 1 THEN cust_id END) AS total_members,\n",
    "        COUNT(DISTINCT CASE WHEN is_member = 0 THEN cust_id END) AS total_non_members,\n",
    "\n",
    "        -- Retained customers: Multi-year presence + at least 12 transactions per year\n",
    "        COUNT(DISTINCT CASE \n",
    "            WHEN active_years >= 1 AND total_transactions / active_years >= 3 AND is_member = 1 \n",
    "            THEN cust_id \n",
    "        END) AS retained_members,\n",
    "\n",
    "        COUNT(DISTINCT CASE \n",
    "            WHEN active_years >= 1 AND total_transactions / active_years >= 3 AND is_member = 0 \n",
    "            THEN cust_id \n",
    "        END) AS retained_non_members\n",
    "    FROM multi_year_customers\n",
    "    GROUP BY store_id\n",
    "),\n",
    "\n",
    "store_retention_analysis AS (\n",
    "    SELECT\n",
    "        store_id,\n",
    "        ROUND((retained_members * 100.0) / NULLIF(total_members, 0), 2) AS member_retention_rate,\n",
    "        ROUND((retained_non_members * 100.0) / NULLIF(total_non_members, 0), 2) AS non_member_retention_rate,\n",
    "        CASE \n",
    "            WHEN (ROUND((retained_members * 100.0) / NULLIF(total_members, 0), 2) >= 40) \n",
    "              OR (ROUND((retained_non_members * 100.0) / NULLIF(total_non_members, 0), 2) >= 20) \n",
    "              THEN 'Loyal-Customer Dominant Store'\n",
    "            ELSE 'Not a Loyal-Customer Dominant Store'\n",
    "        END AS store_customer_category\n",
    "    FROM customer_retention\n",
    ")\n",
    "\n",
    "SELECT * \n",
    "FROM store_retention_analysis\n",
    "ORDER BY member_retention_rate DESC, non_member_retention_rate DESC;\n",
    "\"\"\"\n",
    "\n",
    "df_store_customer_retention = con.execute(query_store_customer_retention).fetchdf()\n",
    "\n",
    "# Display results\n",
    "display(\"Store Retention Analysis\",df_store_customer_retention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b394da4e715e713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:08:45.445593Z",
     "start_time": "2025-03-08T18:08:45.394627Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(x=df_store_customer_retention[\"member_retention_rate\"], \n",
    "                y=df_store_customer_retention[\"non_member_retention_rate\"], \n",
    "                hue=df_store_customer_retention[\"store_customer_category\"], \n",
    "                palette={\"Loyal-Customer Dominant Store\": \"green\", \"Not a Loyal-Customer Dominant Store\": \"red\"},\n",
    "                s=100, alpha=0.7)\n",
    "\n",
    "# Labels and Title\n",
    "plt.axhline(y=20, color='black', linestyle='dashed', label=\"20% Non-Member Retention Benchmark\")\n",
    "plt.axvline(x=40, color='black', linestyle='dashed', label=\"40% Member Retention Benchmark\")\n",
    "\n",
    "plt.xlabel(\"Member Retention Rate (%)\")\n",
    "plt.ylabel(\"Non-Member Retention Rate (%)\")\n",
    "plt.title(\"Store Retention: Membership vs. Non-Membership\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
